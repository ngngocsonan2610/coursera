{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the cost function for our neural network. **\n",
    " \n",
    " The cost function we use for the neural network is going to be a generalization of the one that we use for logistic regression. For logistic regression we used to minimize the cost function $J(\\theta)$ that was $-\\frac{1}{m}$ of this cost function and\n",
    " then plus this extra regularization term here, where this was a sum from J=1 through n, because we did not regularize the bias term $\\theta_0$. \n",
    " \n",
    " For a neural network, our cost function is going to be a generalization of this. Where instead of having basically just one, which is the compression output unit, we may instead have K of them. \n",
    " \n",
    " So here's our cost function. \n",
    " $$J(\\Theta) = -\\frac{1}{m} \\bigg[\\sum_{i=1}^m \\sum_{k=1}^K y_k^{(i)} \\log (h_\\Theta(x^{(i)}))_k + (1 - y_k^{(i)}\\log(1 - (h_\\Theta(x^{(i)}))_k) \\bigg] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\Theta_{ji}^{(l)})^2$$\n",
    "\n",
    " Our new network now outputs vectors in $R^K$, so $h_\\Theta(x) \\in R^K$, where R might be equal to 1 if we have a binary classification problem. \n",
    " - I'm going to use this notation $(h_\\Theta(x))_i$ to denote the ith output. That is, $h_\\Theta(x)$ is a k-dimensional vector and so this subscript i just selects out the ith element of the vector that is output by my neural network. \n",
    " \n",
    " My cost function $J(\\Theta)$ is now going to be the following. \n",
    " - $-\\frac{1}{m}$ of a similar term to what we have for logistic regression, except that we have the sum from K = 1 through K. This summation is basically a sum over my K output. So if I have four output units, that is if the final layer of my neural network has four output units, then this is a sum from k =1 through four of basically the logistic regression algorithm's cost function but summing that cost function over each of my four output units in turn. And so you notice in particular that this applies to $y_k, (h_\\Theta(x^{(i)}))_k$, because we're basically taking the K upper  units, and comparing that to the value of $y_k$ which is that one of those vectors saying what cost it should be, for example: $y_k = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$\n",
    " - And finally, **the second term here is the regularization term**, similar to what we had for the logistic regression. This summation term looks really complicated, but all it's doing is it's summing over these terms $\\Theta_{ji}^{(l)}$ for all values of i, j and l. \n",
    "     - Except that we don't sum over the terms corresponding to these bias values, $\\Theta_0, $like we have for logistic regression. Completely, we don't sum over the terms responding to where i = 0. So that is because when we're computing the activation of a neuron, we have terms like these $\\Theta_{i0}^{(2)}x_0 + \\Theta_{i1}^{(2)}x_1 + ...$. And so the values with a zero there, that corresponds to something that multiplies into an $x_0$ or an $a_0$. And so this is kinda like a bias unit and by analogy to what we were doing for logistic regression, we won't sum over those terms in our regularization term because we don't want to regularize them and string their values as zero. \n",
    "     - But this is just one possible convention, and even if you were to sum over i = 0 up to $S_l$, it would work about the same and doesn't make a big difference. But maybe this convention of not regularizing the bias term is just slightly more common. \n",
    "\n",
    "<img src=\"image/2.2-a.png\" alt=\"drawing\" width=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepairing data for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load MATLAB files\n",
    "from scipy.io import loadmat\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "#%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MATLAB datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('data/ex4data1.mat')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5000, 401) (with intercept)\n",
      "y: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "y = data['y']\n",
    "# Add intercept\n",
    "X = np.c_[np.ones((data['X'].shape[0],1)), data['X']]\n",
    "\n",
    "print('X:',X.shape, '(with intercept)')\n",
    "print('y:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = loadmat('data/ex3weights.mat')\n",
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1 : (25, 401)\n",
      "theta2 : (10, 26)\n",
      "params : (10285,)\n"
     ]
    }
   ],
   "source": [
    "theta1, theta2 = weights['Theta1'], weights['Theta2']\n",
    "print('theta1 :', theta1.shape)\n",
    "print('theta2 :', theta2.shape)\n",
    "params = np.r_[theta1.ravel(), theta2.ravel()]\n",
    "print('params :', params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.random.choice(X.shape[0], 20)\n",
    "plt.imshow(X[sample,1:].reshape(-1,20).T)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an example with Neural Network includes: <br>\n",
    "Input layer size = 400 (20x20 pixels) <br>\n",
    "Hidden layer size = 25 <br>\n",
    "Number of labels = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - Putting it together\n",
    "<img src=\"image/2.2-b.png\" alt=\"drawing\" width=\"460\">\n",
    "<img src=\"image/2.2-c.png\" alt=\"drawing\" width=\"460\">\n",
    "<img src=\"image/2.2-d.png\" alt=\"drawing\" width=\"460\">\n",
    "Cost Function of NN\n",
    "$$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\big[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\big]$$\n",
    "\n",
    "Here's the Regularized cost function that we wrote down\n",
    " $$J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\big[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\big] + \n",
    "\\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\Theta_{ji}^{(l)})^2$$\n",
    "\n",
    "Regularized Cost Function (with theta_1 and theta_2 in this example)\n",
    "$$ J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}\\bigg[-y^{(i)}_{k}\\, log\\,(( h_\\theta\\,(x^{(i)}))_k)-(1-y^{(i)}_k)\\,log\\,(1-h_\\theta(x^{(i)}))_k)\\bigg] + \\frac{\\lambda}{2m}\\bigg[\\sum_{j=1}^{25}\\sum_{k=1}^{400}(\\Theta_{j,k}^{(1)})^2+\\sum_{j=1}^{10}\\sum_{k=1}^{25}(\\Theta_{j,k}^{(2)})^2\\bigg]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid gradient\n",
    "#### $$ g'(z) = g(z)(1 - g(z))$$\n",
    "where $$ g(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    return(sigmoid(z)*(1-sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, features, classes, reg):\n",
    "    \n",
    "    # When comparing to Octave code note that Python uses zero-indexed arrays.\n",
    "    # But because Numpy indexing does not include the right side, the code is the same anyway.\n",
    "    theta1 = nn_params[0:(hidden_layer_size*(input_layer_size+1))].reshape(hidden_layer_size,(input_layer_size+1))\n",
    "    theta2 = nn_params[(hidden_layer_size*(input_layer_size+1)):].reshape(num_labels,(hidden_layer_size+1))\n",
    "\n",
    "    m = features.shape[0]\n",
    "    y_matrix = pd.get_dummies(classes.ravel()).as_matrix() # 5000x10\n",
    "    \n",
    "    # Feedforward\n",
    "    # Cost\n",
    "    a1 = features # 5000x401\n",
    "        \n",
    "    z2 = theta1.dot(a1.T) # 25x401 * 401x5000 = 25x5000 \n",
    "    a2 = np.c_[np.ones((features.shape[0],1)),sigmoid(z2.T)] # 5000x26 \n",
    "    \n",
    "    z3 = theta2.dot(a2.T) # 10x26 * 26x5000 = 10x5000 \n",
    "    a3 = sigmoid(z3) # 10x5000\n",
    "    \n",
    "    J = -1*(1/m)*np.sum((np.log(a3.T)*(y_matrix)+np.log(1-a3).T*(1-y_matrix))) + \\\n",
    "        (reg/(2*m))*(np.sum(np.square(theta1[:,1:])) + np.sum(np.square(theta2[:,1:])))\n",
    "\n",
    "    # Back propogation\n",
    "    # Gradients\n",
    "    d3 = a3.T - y_matrix # 5000x10\n",
    "    d2 = theta2[:,1:].T.dot(d3.T)*sigmoidGradient(z2) # 25x10 *10x5000 * 25x5000 = 25x5000\n",
    "    \n",
    "    delta1 = d2.dot(a1) # 25x5000 * 5000x401 = 25x401\n",
    "    delta2 = d3.T.dot(a2) # 10x5000 *5000x26 = 10x26\n",
    "    \n",
    "    theta1_ = np.c_[np.ones((theta1.shape[0],1)),theta1[:,1:]]\n",
    "    theta2_ = np.c_[np.ones((theta2.shape[0],1)),theta2[:,1:]]\n",
    "    \n",
    "    theta1_grad = delta1/m + (theta1_*reg)/m\n",
    "    theta2_grad = delta2/m + (theta2_*reg)/m\n",
    "    \n",
    "    return(J, theta1_grad, theta2_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annguyen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28762916516131887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization parameter = 0\n",
    "nnCostFunction(params, 400, 25, 10, X, y, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annguyen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3837698590909236"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization parameter = 1\n",
    "nnCostFunction(params, 400, 25, 10, X, y, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19661193324148185,\n",
       " 0.2350037122015945,\n",
       " 0.25,\n",
       " 0.2350037122015945,\n",
       " 0.19661193324148185]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sigmoidGradient(z) for z in [-1, -0.5, 0, 0.5, 1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
